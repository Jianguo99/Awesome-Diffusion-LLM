# Diffusion-LLM-Papers

Weâ€™ve collected a series of papers on Diffusion Language Models. 

Since our time is limited and we can't cover everything, **please feel free to submit a pull request to contribute.**


## Theoretical Basis
**Deep Unsupervised Learning using Nonequilibrium Thermodynamics**  
2015-3-12, [Paper](https://arxiv.org/abs/1503.03585)

**Structured Denoising Diffusion Models in Discrete State-Spaces**  
2021-7-7, [Paper](https://arxiv.org/abs/2107.03006)

**Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution**  
2023-10-25, [Paper](https://arxiv.org/abs/2310.16834)

**Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data**  
2024-6-6, [Paper](https://arxiv.org/abs/2406.03736)

**Simplified and Generalized Masked Diffusion for Discrete Data**  
2024-6-6, [Paper](https://arxiv.org/abs/2406.04329)

**Simple and Effective Masked Diffusion Language Models**  
2024-6-11, [Paper](https://arxiv.org/abs/2406.07524)


## Foundation Model
**LLaDA: Large Language Diffusion Models**  
2025-2-14, [Paper](https://arxiv.org/abs/2502.09992)

**Dream 7B**  
2025-4-2, [Paper](https://hkunlp.github.io/blog/2025/dream/)


## Multimodal Model
### Multimodal Understanding
**LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning**  
2025-5-22, [Paper](https://arxiv.org/abs/2505.16933)

**LaViDa: A Large Diffusion Language Model for Multimodal Understanding**  
2025-5-22, [Paper](https://arxiv.org/abs/2505.16839)

**Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding**  
2025-5-22, [Paper](https://arxiv.org/abs/2505.16990)

### Unified Multimodal Model
**MMaDA: Multimodal Large Diffusion Language Models**  
2025-5-21, [Paper](https://arxiv.org/abs/2505.15809)


## Fast Sampling
**dKV-Cache: The Cache for Diffusion Language Models**  
2025-5-21, [Paper](https://arxiv.org/abs/2505.15781)

**Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding**  
2025-5-22, [Paper](https://arxiv.org/abs/2505.16990)

**dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching**  
2025-5-22, [Paper](https://github.com/maomaocun/dLLM-cache?tab=readme-ov-file)

**Variational Autoencoding Discrete Diffusion with Enhanced Dimensional Correlations Modeling**  
2025-5-23, [Paper](https://arxiv.org/abs/2505.17384)

**Accelerating Diffusion Language Model Inference via Efficient KV Caching and Guided Diffusion**  
2025-5-27, [Paper](https://arxiv.org/pdf/2505.21467)

**Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding**  
2025-5-28, [Paper](https://nvlabs.github.io/Fast-dLLM/paper/fast_dllm.pdf)

**Accelerated Sampling from Masked Diffusion Models via Entropy Bounded Unmasking**  
2025-5-30, [Paper](https://arxiv.org/abs/2505.24857)

**Accelerating Diffusion LLMs via Adaptive Parallel Decoding**  
2025-5-31, [Paper](https://arxiv.org/abs/2506.00413)

**Esoteric Language Models**  
2025-6-2, [Paper](https://arxiv.org/abs/2506.01928)

**Accelerating Diffusion Large Language Models with SlowFast Sampling: The Three Golden Principles**  
2025-6-12, [Paper](https://arxiv.org/abs/2506.10848)


## Reinforcement Learning
**d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning**  
2025-4-16, [Paper](https://arxiv.org/abs/2504.12216)

**Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models**  
2025-5-15, [Paper](https://arxiv.org/abs/2505.10446)

**LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models**  
2025-5-25, [Paper](https://arxiv.org/abs/2505.19223)


## Long Context
**LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs**  
2025-6-17, [Paper](https://arxiv.org/abs/2506.14429)


## Variable Length
**DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-Size Canvas**
2025-7-15, [Paper](https://hkunlp.github.io/blog/2025/dreamon/)

**Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models**  
2025-8-4, [Paper](https://arxiv.org/abs/2508.00819)


